\subsection{Low-Overhead Portfolios for Combining Tie-Breaking Strategies}

As noted above, it is unknown prior to the search where the goal node
exists in a plateau. However, the previous experiment showed that the
best depth-based second-level tiebreaking among \ld, \fd, \rd depends on
the domain characteristics and none of \ld, \fd, \rd dominated each
other.  Here, one natural idea is to use a portfolio approach which
combine these three.

The simplest possible portfolio approach would be a standard algorithm portfolio
which executes two completely independent \astar processes $A_1$ and $A_2$ in parallel, where $A_1$ uses tiebreaking strategey $S_1$ and $A_2$ uses tiebreaking strategy $S_2$, and CPU resources are allocated equally to $A_1$ and $A_2$.
The portolio would terminate when either $A_1$ or $A_2$ finds a goal state.
Let $T_1$ be the time that $A_1$ requires to solve instance $I$, and $T_2$ be the
time $A_2$ requires to solve instance $I$. Then, the total CPU time
required by the portfolio to solve instance $I$ is $2\times\min(A_1,A_2)$. This approach to combining multiple strategies is the standard algorithm portfolio proposed and analyzed in \cite{HubermanLH97,GomesS01}, and has also recently been called ``dovetailing'' and applied to combine multiple IDA* and \astar  \cite{ValenzanoSSBK10}. %TODO: remove the dovetailing reference after the paper is accepted -- the dovetailing authors were unaware of the HubermanLH97 paper...

On one hand, this simple portfoio approach has the advantage of mitigating worst-case risk -- as shown in \refig{plateau}, sometimes, the ratio between $T_1$ and $T_2$ is very large (e.g., $T_2 > 10\times T_1$) and choosing the wrong strategy has a very high penalty, so this portfolio strategy guarantees that the CPU usage is never more than twice that of using the faster strategy.
On the other hand, this simple portfolio will always require twice the
CPU time of the faster strategy.
%% removed, since LOP does not solve this problem
% Furthermore, the portfolio requires twice the RAM resources, which is a major disadvantage in memory-bound algorithms such as \astar.

We propose a new, \emph{Low-Overhead Portfolio} (LOP) implementation which can be used to implement a portfolio of tie-breaking strategies with significantly less overhead.
% 
Conceptually, a LOP for \astar is a portfolio composed of multiple
independently executing \astar where each \astar has completely separate
open/closed list, using a different tiebreaking strategy but sharing a
global cache for heuristic function values. Whenever a search engine
evaluates a state, it first checks the cache and reuses the result if
possible.  The current implementation is sequential -- each search
engine takes turns evaluating states. The algorithm finishes when some
engine finds the solution. Note that it takes turns \emph{evaluating}, not
\emph{expanding}, the states --- If we alternate the expansion, 
the node evaluation effort would not be evenly
distributed among \astar{}s, due to the difference in the number of
successor states of each node. There is a small pool for each queue
storing the nodes which are expanded
but not yet evaluated. Evaluation happens in turns, and if the pool is
exhausted, the expansion occurs as necessary in order to evaluate
more nodes.

Low-Overhead Portfolios offer some attractive tradeoffs,
particularly when runtimes are dominated by state evaluation, as is the case when searching with 
expensive heuristics such as LM-cut or recently proposed LP-based heuristics \cite{PommereningRHB14,ImaiF14}.

First, although the effort to insert/extract nodes from multiple
open/closed lists is doubled, these overheads are neglibigle when the
heuristic is expensive (see \refig{ffff}, left).

Second, although maintaining multiple open/closed lists requires additional memory,
when the heuristic is expensive enough, runtime becomes a bigger issue
than memory exhaustion  -- we show that with a 30 minute time limit, LOP
configurations do not exhaust memory more often than the other
configurations does (\refig{ffff}, right).

Third, node evaluation overheads for $f < f^*$ are eliminated due to the $h$-cache.
Recall that \astar always evaluates all states whose $f$ costs 
below $f^*$. Since the heuristic function $h$ and in turn $f=g+h$ are
the same among tiebreaking strategies, they evaluate the same set of
nodes with $f<f^*$. Unlike a standard portfolio implementation where 
nodes with $f<f^*$ would be evaluated multiple times, there is no evaluation overhead in a LOP
for nodes with $f<f^*$.
This is not
affected by the reopening caused by inconsitent heuristics either,
because the $h$-value is cached.

%% Third, since the search terminates when \emph{some} engine finds a
%% solution, and since the evaluation happens in turns, the search effort
%% within the final plateau is upper bounded by \emph{twice} the
%% \emph{minimum} of the search efforts required by each of \ld-\lifo or
%% \ld-\fifo engine alone.  Evaluating the same nodes in different engines
%% also reduces the effort to less than twice due to caching.  This is
%% desirable because, as we saw in the Results section, in some domains the
%% gap between the best and worst tiebreaking strategy can be more than 10
%% times (Openstacks, for example).  When there are $n$ engines, then this
%% increases to $n\times$ minimum amount of effort which would be spent by
%% each single engine alone.

Finally, in the worst case, the total number of nodes evaluated by a LOP is bounded by the number of nodes with $f \leq f^*$, which is the same as the worst-case behavior of \astar using the worst possible tie-breaking strategy.
This can occur  when all tiebreaking
strategies perform poorly  and they all evaluates the goal node in the
final iteration.

\subsubsection{Evaluating LOPs}

As we see in the previous section, the planner performance is greatly
affected by the tiebreaking criteria, especially when the search plateau
is huge, which is more often the case with the more practical,
cost-minimization domains.
% 
Also, the different depth-based tiebreakings are not dominating
each other and is unpredictably affected by the domain characteristics.
% 
Therefore, the LOP strategy should avoid the
worst-case scenario caused by bad tiebreaking, and quickly find the solution.

First, we show that the doubled cost of insertion and deletion by LOP is
negligeble.  We verified this by comparing the runtime of single \astar
with a LOP consisting of two same \astar, where all three \astar{}s
using the idential configuration ($[f,h,\fifo]$ with $h=$\lmcut). The
results in \refig{ffff} show that the extra cost of duplicated effort
is negligeble.

\begin{figure}[tb]
 \centering \relsize{-2}
 \includegraphics{tables/aaai16-30min/aaai16prelim3/time-nokey-lmcut_ff-lmcut_ffff.pdf}
 \includegraphics{tables/aaai16-30min/aaai16prelim3/mem-nokey-lmcut_ff-lmcut_ffff.pdf}
 \caption{Comparison of the runtimes (left) and memory usage (right) by
 single $[f,h,\fifo]$ and a LOP engine with 2 different instances of
 $[f,h,\fifo]$. Each line shows $\times 2,4,6\ldots$ boundary.
 The runtime gap was on average 1.03x and at most x1.29.
 The memeory usage gap was on average 1.14x and at most x1.56.
 We ignore the subsecond differences.}  \label{ffff}
 % this is from 30 min data. 9/7
\end{figure}

Next, we evaluated our LOP
strategy with selective combinations of two or three tiebreakings.
The configuration shown as ``lmcut m2'', ``lmcut m3'', ``mands m2'',
``lmcut m3'' are respectively the portfolio of
$[\ld,\fifo]$ + $[\rd,\lifo]$, $[\ld,\fifo]$ + $[\ld,\ro]$ + $[\rd,\lifo]$,
$[\ld,\fifo]$ + $[\rd,\ro]$, $[\ld,\fifo]$ + $[\rd,\ro]$ + $[\ld,\lifo]$. These
portfolios are selected by hand based on the previous results.
% LOP is able to avoid the accidental bias
Results in \reftbl{portfolio-coverage}
shows a significant improvements compared to the results by each search
engine alone.
% 
Also, \refig{portfolio-runtime} shows the number of evaluations of these
tiebreakings compared to each search engine alone.  It shows that
LOP acutally follows the expected behavior and the theoretical
bounds: the evaluation never exceeds twice/thirds of the single
search engine.

\begin{table}[tb]
 \centering \relsize{-2}
 \input{tables/aaai16-30min/aaai16prelim3_zerocost_2zerocost/1-1-multi-lmcut.tex}
 \caption{Coverage results comparing some LOP combinations and the
 single strategies under the portfolio. The seeds are fixed to 1 in these instances.}
 \label{portfolio-coverage}
\end{table}

\todo{the evaluations are double-counted for LOP}

\begin{figure}[tb]
 \centering
 \relsize{-2}
 \includegraphics{tables/aaai16-multi-ldrd/zerocost/evaluated-nokey-lmcut_ldrd_random-lmcut_ld_random.pdf}
 \includegraphics{tables/aaai16-multi-ldrd/zerocost/evaluated-nokey-lmcut_ldrd_random-lmcut_rd_random.pdf}
 \caption{Comparson of node evaluation between LOP $[\ld,\ro]$ +
 $[\rd,\ro]$ and the single strategy $[\ld,\ro]$ and $[\rd,\ro]$, on
 zerocost instances.}  \label{portfolio-runtime}
\end{figure}


