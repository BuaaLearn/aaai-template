
% Take extra care in avoiding ``expansion'' -- stick to ``evaluation''

\begin{abstract}
Despite the recent improvements in admissible heuristic search techniques
in classical planning, it is known that the the exponential growth of
search plateau in A* is unavoidable even under the optimistic assumption.
 % 
We investigate various existing myth on tiebreaking
strategies and propose simple yet effective methods for improving the
search performance within plateau.
 % 
 % 
 They do not depend on any particular heuristic, nor
 on multi-heuristic portfolio.
 They work even if the heuristic
 function no longer provides useful information.
 % Moreover, they do not even try to obtain any further information from
 % the domain.
 We empirically evaluate our strategies against state-of-the-art admissible planner.
\end{abstract}

\section{Introduction}
%Motivation: The Importance of the Last Frontier in A* and Domains with Large Plateaus
\label{sec-1}



%\subsubparagraph{\astar and perfect heuristics}

This paper investigates tie-breaking strategies for \astar.
\astar is a standard search algorithm for finding an optimal-cost path 
from an initial state $s$ to some goal state $g \in G$ in a search space represented as a graph \cite{hart1968formal}.
In each iteration, \astar selects and \emph{expands} a node $n$ from the OPEN priority queue.
\astar selects and expands the node which has the lowest $f$-cost, where for node $n$, $f(n)$ is the sum of  $g(n)$, the cost of the current path from the start state to $n$, and $h(n)$, a heuristic estimate of the cost from $n$ to a goal state.
\astar returns an optimal solution when $h$ is admissible, i.e., when it
never overestimates the true distance to the goal $h^*$.

In order to guarantee solution optimality, \astar expands all
nodes with $f(n) < f^*$, where $f^*$ is the true cost of the optimal solution.
%All nodes with $f(n) = k$ are expanded before any node with $f(n) > k$ are expanded.
%Thus, after all nodes with $f(n) < f^*$ have been expanded, 
\astar expands \emph{some} of the nodes with $f(n) = f^*$, and never expands a node with $f(n) > f^*$.
Thus, the \emph{effective search space of \astar}, $N$, is the set of nodes with 
$f(n) \leq f^*$, and
much of the work in the AI search and planning literature  has focused on reducing the size of $N$ by
developing more accurate, admissible heuristic functions.

In many problems, the size of the \emph{last frontier}, the set of nodes with $f(n)=f^*$, accounts for a significant portion of $A$.
\refig{fig:plateau-noh} plots the number of states with $f(n) = f^*$ (y-axis)
versus the number of states with $f(n) \leq f^*$
for a set of 1104 benchmark problem instances from the ICAPS International Planning Competition (IPC1998-2011).
For many instances in \refig{fig:plateau-noh},  a large fraction of the nodes with $f(n) \leq f^*$ have $f(n)=f^*$.
For example, in the Openstacks domain, almost all states with $f(n) \leq f^*$ have cost $f^*$.
In such domains, the behavior of \astar on the last frontier is critical -- the policy for deciding which nodes to expand in the last frontier can have a significant impact on the performance of \astar.

\begin{figure}[htb]
 \centering \relsize{-3} 
 \includegraphics{tables/aaai16-frontier/aaai16prelim3/lmcut_frontier_noh-front.pdf}
 \caption{
 The number of the nodes with cost $f=f^*$ (y-axis) compared to the
 total number of nodes in the search space with cost $f\leq f^*$ on 1104 IPC benchmark problems
(search space analyzed using Fast Downward with \lmcut heuristic, slightly modified to generate all nodes with cost $f^*$).}
\label{fig:plateau-noh}
\end{figure}

In this paper, we focus on the \emph{tie-breaking} policy used by \astar, which selects a node to expand among nodes with the same $f$-cost.
Since \astar expandes all nodes with $f$-cost less than $f^*$ before expanding any nodes with with cost $f^*$, 
the tie-breaking poicy only affects performance when considering the last frontier (nodes with cost $f^*$).
Although there has not been much previous \emph{in-depth} work on tie-breaking policies,
it is widely believed that among nodes with cost $f(n) = f^*$, ties should be broken according to $h(n)$, i.e., nodes with smaller $h$ values should be expanded first.
While this is a useful rule of thumb in many domains,
it turns out that tie-breaking requires more careful consideration, particularly for problems with large \emph{plateaus} -- regions of the search space with the same cost.

In this paper, we first show several important findings regarding the
existing tiebreaking strategy for \astar as follows.
% 
First, in implementing the open list of \astar, priority queue which holds
LIFO-buckets for each $f$ is more efficient than that holds FIFO-buckets.
% 
Second, with LIFO-based implementation, $h$-based tiebreaking which
frequently appears in the heuristic search literatures have little
impact on the performance.
% 
\todo[
Third, the LIFO-based bucket implementation and $h$-based tiebreaking
both share the greedy search pattern within the plateau of the
search space.]{this is not shown yet}

Next, based on these observations, we propose three tiebreaking methods
based on the \emph{depth} within the plateau.  From this result, we show
that the performance of above LIFO tiebreaking can be explained by its
depth-first strategy and not by the machine-level efficiency of LIFO
implementation itself.  Also, the performance comparison of different
depth-based strategies showed that they are not dominating each other.

Finally, based on the absence of dominance relationship, we propose a
new class of portfolio strategy which alternates between several
tiebreaking methods.
% 
With this portfolio strategy,
the number of evaluations of nodes with $f<f*$ is exactly the same as
in any single tiebreaking strategies.
Also, it has a theoretical guarantee that
the number of evaluations of nodes with $f=f*$ is at most $N$ times the \emph{minimum} 
of the evaluations required by $N$ strategies in the portfolio.
To put it simply, this portfolio does not need additional computation
and we get a speedup for free (aside from the negligeble differences).
% Also, it is characteristic in that it works with a single heuristic function.

The rest of paper is organized as follows: The next section describes the
preliminary backgrounds of \astar.
Next we compares several trivially-simple and well-known tiebreaking
methods on top of Fast Downward to show that even such a small
difference significantly affects the performance on domains with
large plateaus.
Next we propose a novel depth-aware tiebreaking methods and empirically
show that it outperforms previous strategies.
Then we proceed to evaluate the tiebreaking portfolio.
We finally conclude with a discussion on the future work.

\section{Preliminaries and Background}

\subsection{Domains with Zero-cost Actions: Applications and Motivation}

\todo*{Add several paragraphs explaining why domains with zero-cost actions are an important, practical class of problem, e.g., energy consumptin minimization.}

% XXX I'm commenting out the paragraphs below because:
% (1) A review of heuristic functions for domain-independent learning is not really
% necessary for this AAAI submission. 
% (2) It's better if this paper is not so strongly associated with the ICAPS community only -- this work applies in general to search with A*, and is not strongly tied to almost-perfect heuristics, lmcut, m&s, etc.

Historically, the study of the shortest path finding algorithms has
started on the unit cost domains as the simplest case, where every
search edge has a cost 1,
% . Experimental study of \astar was somewhat biased to
% the unit-cost domains
such as 24-puzzle, Rubik's Cube etc.
There are also several problems with non-unit costs, sometimes
artificially but also sometimes naturally, such as in multiple
sequence alignment (MSA).

In the plannning community, the first introduction of non-unit domain in
the cometition is IPC-02. Currently most competition domains have the
non-unit costs. 
Notably, most actions in these domains have nonzero positive costs.
% 
%  Although some of these domains have non-unit costs,
% those domains are sometimes \emph{mostly} unit cost. For example, TPP
% has many actions with a cost 1 and some actions have cost 10.
% 
% The idea here is to differentiate the important actions from the less
% important actions.
% 
For example, Elevator and Miconic in the benchmark domains minimize the
runtime of moving the passengers up and down.  Actions in which the
elevator travels the long distance take longer runtime.  When concerned
with the runtime, it is reasonable to assign nonzero positive cost to
every actions, since every actions are supposed to at least consume a
fraction of time.

However, such formulation is not suitable for the general type of cost
minimization in which the target is not the runtime.  For example, when
you try to minimize the energy consumption by the elevators, many
actions would have zero-cost --- it does not consume electricity for
either moving the elevator down, boarding or leaving the passenger.
 
The same thing applies to the transportation-type and assembly-type
domains like logistics and Woodworking, respectively. They are runtime
minimization domains in which driving and manual labor, or cutting and
painting, are equally measured by the single runtime metric.
% 
However, a few modifications to the action costs will turn them into
cost-minimization domains, in which the target is the fuel consumption
(logistics) or wood usage (Woodworking). From the practical point of
view, cost minimization domains would have wider interests compared to
the simple runtime minimization.

Openstacks domain we noted in the previous section is a cost
minimization domain first introduced in IPC-06. It is targeted at
minimizing the number of stacks used and it has many zero-cost
actions. These zero-cost actions prevent the heuristics from producing
informative guidance. The \sota heuristic functions such as \lmcut
\cite{Helmert2009} and M\&S \cite{helmert2007flexible} fail to find a
meaningful estimate because \lmcut fails to find a good cost
partitioning with non-zero values, and most edges in the abstraction
space of M\&S have zero costs.

% Currently, most benchmark domains except Openstacks and Cybersec do not
% have the large plateau thanks to the powerful heuristic estimates (which
% is verified in the later section). However, limiting our effective
% experiments only to 2 domains would bias our observation. To avoid this
% issue, we created several domains where the \sota heuristic functions
% fail to provide a menaingful guidance.

% One important characteristics shared by Openstacks and Cybersec is that they both
% have large number of zero-cost actions.
 % In such situations, both LMcut
% and M\&S fail to find a meaningful heuristic estimate because LMcut fails to
% find a good cost partitioning with non-zero values, and most edges in the abstraction space of
% M\&S have zero costs.

% We therefore modified various domains to have many zero-cost actions.
% For example, miconic-up is a domain which minimizes the energy
% consumption caused by ``up'' action, which moves the elevator up, and
% all other actions have zero-cost. Another example is driverlog-fuel, where only
% the ``drive'' action has cost 1 and all other actions are zero-cost.
% This in fact reflects the practical application compared to the original
% unit-cost domains where driving and manual labor is equally accounted.
% Oddly, although some planners have options which treats actions as if
% they are unit-costs, and describe such options as ``inadmissible'',
% solving domains which are unit-cost by origin is not called
% ``inadmissible''. Above modification addresses this problem.

In this paper, we therefore modified various domains to have many
zero-cost actions.  For example, miconic-up is a domain which minimizes
the energy consumption caused by ``up'' action, which moves the elevator
up, and all other actions have zero-cost.  Modification was done in a
practically reasonable manner in a sense of cost minimization. Most
transportation-type domains are modified so that they use less
fuel. Assembly-type domains are modified so that it minimizes the
resource usage such as ink or wood.  \todo[We also modify a same domain
in the different minimization criteria, in order to avoid the bias on a
particular domain formulation.]{It's not tested yet}

\subsection{Tiebreaking Strategies in \astar}

Aside from the heuristic function, most best-first family of search
algorithms, including \astar, IDA* and so on, have a tiebreaking criteria which is used
when two nodes have the same $f$ value.
There are two mainstreams of tiebreaking criteria in these algorithms:
$h$-based tiebreaking and LIFO-tiebreaking.

The original \astar paper \cite{hart1968formal} explains the default
tiebreaking in \astar as ``always in favor of any node $n \in T$ [goal
node]'', implying that it break ties by choosing the nodes which are
nearer to the goal, which means larger $g$ and smaller $h$.
\citeauthor{Korf1985depth} uses $h$-based tiebreaking in the context of WA*
\cite{korf1993linear}.  \citeauthor{hansen2007anytime} claim it is
``well-known that \astar achieves best performance when it breaks ties
in favor of nodes with least h-cost'' \cite{hansen2007anytime}, and
\citeauthor{holte2010common} also writes ``\astar breaks ties in favour
of larger g values, as is most often done'' \cite{holte2010common}.
% \citeauthor{felner2011inconsistent} also assume ``ties are broken in
% favor of low h-values'' in describing Bidirectional Pathmax for \astar.
\citeauthor{burns2012implementing} also break ties ``preferring high
g'', which means low $h$. They also writes ``The reasoning is that the
goal can be found more quickly in the final $f$ layer of search''. We
assume this is a consensus among the researcher of forward heuristic
search, although not extensively investigated yet.

Analysis on LIFO-based tiebreaking is not as abundant as in $h$-based
tiebreaking and is largely forgotten.
\citeauthor{Korf1985depth} assumes LIFO ordering in describing \astar,
as ``\astar employes the tie-breaking rule of 'most
recently generated''' \cite{Korf1985depth}.
\citeauthor{burns2012implementing} did not mention anything about how
the bucket of nodes with the same $h$-value is implemented, but from their
open-sourced implementation, they use LIFO for second-level tiebreaking. 
In contrast, current implementation of \sota \astar based planner Fast
Downward \cite{Helmert2006} uses FIFO-queue for implementing the bucket
of $h$-based tiebreaking, again giving no explanation to this decision.


However, in fact, these tiebreaking methods are not necessary when we
are only concerned with maintaining the optimality. In particular, the
choise of FIFO or LIFO tiebreakings usually have little to no
explatation, and are presumably a result of heuristic selection, for
either the simplicity of the implementation or the minor performance difference
caused by memory access pattern, and have no theoretical background.
% In particular, we first observed that this FIFO order has not legitimate reason to support.








\section{Depth-based Tiebreaking}

In order to solve this kind of problem with a large final plateau, the
planner needs to run an efficient knowledge-free search within the
plateau.  One useful measure for controlling the search in this
situation is the number of steps from the entrance of the plateau.

The \emph{depth} of a node is an integer equal to the depth of its
parent node plus one. If the parent node is from the other plateau,
e.g., different $f$-value, or different $h$-value used for the first
tiebreaking, the depth is 0.  With this simple notion of depth, we
developed three variations of the second level tiebreaking method,
called FirstDepth(FD), RandomDepth(RD) and LastDepth(LD). In all three
methods, the nodes are stored in the bucket associated with particular
depth.  However, upon expansion, they choose the bucket with the smallest,
a random, or the largest depth to pick a node from, respectively.
Each variation has 3 possibilities of implementing their buckets, namely
FIFO, LIFO and Random Order(RO), resulting in 9 configurations ---
FD-FIFO, FD-LIFO, FD-RO, LD-FIFO --- and so on.

These tiebreaking methods trivially maintains the admissibility because
it works only within the same $f$-value and does not alter the expansion
order wrto $f$-value.

Note that these strategies are not universally dominating each other.
%This is intentional because, 
In the knowledge-free search within the plateau, all nodes have the same
$f$-value and it is impossible to guess whether the goal is near, far
away or in a particular distance from the entrance. In the first case,
the search should be focused around the entrance favoring the smaller
depths, and the behavior should be much like breadth-first, and it
corresponds to FirstDepth. In the second case, the planner should
greedily explore the various area of the plateau by preferring larger
depth, much like in depth-first, and corresponds to LastDepth. In the
final case where the goal node is in a particular depth, choosing the
random depth seems the safest practice. This corresponds to the case
where RandomDepth would perform better.
% 
This is verified in the later experiments.

Also note that, the node evaluation orders of FD-FIFO and LD-LIFO are
exactly the same as FIFO and LIFO, i.e., those without the depth-based
tiebreaking.  This is because, LIFO expands the most recently evaluated
states, which always has the largest depth, and FIFO expands the oldest
evaluated states, which always has the smaller depth.

% This ``greediness'' is different from the normal
% sense of ``greedy search'' --- since this greediness only holds within
% the plateau, admissibility is still maintained.
 
\section{MultiSearch }

As noted above, it is unknown prior to the search where the goal node
exists in a plateau.
However, the best tiebreaking strategy seems to be affected by the domain
characteristics, as we show in the evaluation section.

Since the performance of a tiebreakig strategy depends on the domain, and there is no clear dominance relationship among the tiebreaking strategies, one natural 
idea is to use a portfolio approach which combine several tiebreaking strategies.

The simplest possible portfolio approach would be a standard algorithm portfolio
which executes two completely independent A* processes A1 and A2 in parallel, where A1 uses tiebreaking strategey S1 and A2 uses tiebreaking strategy S2, and CPU resources are allocated equally to A1 and A2.
The portolio would terminate when either A1 or A2 finds a goal state.
Let T1 be the time that A1 requires to solve instance I, and let T2 be the time A2 requires to solve instance I. Then, the total CPU required by the portfolio to solve instance I is 2min(A1,A2). This approach to combining multiple strategies is the standard algorithm portfolio proposed and analyzed in \cite{HubermanLH97,GomesS01}, and has also recently been called ``dovetailing'' and applied to combine multiple IDA* and A*  \cite{ValenzanoSSBK10}. %TODO: remove the dovetailing reference after the paper is accepted -- the dovetailing authors were unaware of the HubermanLH97 paper...

On one hand, this simple portfoio approach has the advantage of mitigating worst-case risk -- as shown in XXX, sometimes, the ratio between T1 and T2 is very large (>10x) and choosing the wrong strategy has a very high penalty, so this portfolio strategy guarantees that the CPU usage is never more than twice that of using the faster strategy.
On the other hand, this simple portfolio will always require twice the CPU time of the faster strategy. Furthermore, the portfolio requires twice the RAM resources, which is a major disadvantage in memory-bound algorithms such as A*.

We propose a new, {\emph Low-Overhead Portfolio} (LOP) implementation which can be used to implement a portfolio of tie-breaking strategies with significantly less overhead.
Conceptually, a LOP for A* is a portfolio composed of multiple independently executing threads of A*  where each thread  executes independently using a different tiebreaking strategy but which share a cache for heuristic function values.
The actual implementation is as follows:
The LOP simulates
multiple search engines using the same heuristic function, but with the
different tiebreaking strategies.  Each engine has completely separate
open list and closed list.  However, there is a globally shared hash
table which caches every results of the heuristic function.  Whenever a
search engine evaluates a state, it checks if the result of a heuristic is
already computed, and if so, it reuses the result.  Each search engine
evaluates a state in turns, sequencially, so there is no parallelism
involved. The algorithm finishes when some engine finds the solution.


The LOP has several interesting characteristics.  First,
although the amount of memory used for the open/closed list is doubled,
and the effort to push/pop the search nodes is also doubled, the
computation of \lmcut is so heavy that those wasted efforts are
negligeble.  We verify this in the results section.

Second, if we ignore the negligeble cost of insertion and deletion to
the open/closed list, we do not have to pay the extra cost evaluating
the heuristic function for states $f<f^*$ thanks to the caching.
Recall that \astar must always evaluate the states whose $f$ values are
below $f^*$. Since the heuristic estimate $h$, and in turn $f=g+h$, is
the same among the tiebreaking strategies, they evaluate the same set of
nodes in $f<f*$.  Therefore, in region $f<f*$, our caching mechanism
fully works and completely eliminates the possibility of extra
evaluation caused by adding another queues.  Note that, this is not
affected by the reopening of the node caused by inconsitent heuristics
since the $h$-value is cached.

%% Third, since the search terminates when \emph{some} engine finds a
%% solution, and since the evaluation happens in turns, the search effort
%% within the final plateau is upper bounded by \emph{twice} the
%% \emph{minimum} of the search efforts required by each of LD-LIFO or
%% LD-FIFO engine alone.  Evaluating the same nodes in different engines
%% also reduces the effort to less than twice due to caching.  This is
%% desirable because, as we saw in the Results section, in some domains the
%% gap between the best and worst tiebreaking strategy can be more than 10
%% times (Openstacks, for example).  When there are $n$ engines, then this
%% increases to $n\times$ minimum amount of effort which would be spent by
%% each single engine alone.
Finally, thanks to the full caching, the worst case evaluation is upper
bounded by the total number of nodes with $f\leq f^*$, which is same as
the case of single engine alone. This happens when all tiebreaking
strategies perform quite poor and they all evaluates the goal node in the
final iteration.

\section{Experimental Results}


We tested various tiebreaking strategies. In the following sections, we
use a convenient array-based notation of a combination of tiebreaking
strategy.  For example, $[f,h,\fd,\fifo]$ denotes standard \astar with
$h$-based first-level tiebreaking, FirstDepth second-level tiebreaking and FIFO
third-level tiebreaking.

All planners are based on the latest Fast Downward code base, and all
experiments are run using 30 minutes runtime cutoff with 2GB memory
limit. Also, experiments are conducted on Xeon E5410@2.33GHz CPUs.

Our experimental results include 28 standard benchmark domains with 1104
problems, 16 \emph{zerocost} domains with 640 problems, 16
\emph{shuffled-zerocost} domains which have the suffled action ordering
in the domain definition.

% 
% moved domain descriptions
% 
% 
% 

\subsection{Comparison of Bucket Implementations}

We first compared the default $[f,h,\fifo]$ with $[f,h,\lifo]$ and
$[f,h,\ro]$ in \reftbl{single-coverage} (Left).  We observed that even
such a slightest difference can change the performance significantly on
some domains. Due to the space limitation, we show only the domains
where the difference was observed. Full table is available in the
supplemental material.

\begin{table}[htbp]
 \centering \relsize{-3}
 \input{tables/aaai16-5min/aaai16prelim3/1-1-basic-queues.tex}
 \input{tables/aaai16-5min/aaai16prelim3/1-1-basic-queues-noh.tex}
 \caption{Experiments comparing the performance of FIFO, LIFO and Random
 second-level tiebreaking, with (left) and without (right) the
 conventional first-level $h$-tiebreaking.  For the space reason, we
 omitted those domains whose results are the same (Full results are
 available in the supplemental material.) Each cell denotes the problem
 solved with 30 min, 2GB setting. \textbf{Boldface} denotes the case
 where it achieved the best result among configurations.}
 \label{single-coverage}
\end{table}

\refig{f-h-eval} gives us a more fine-grained analysis by comparing the
number of node evaluation (computations of \lmcut) on
different tiebreakings.

\begin{figure}[htbp]
 \centering \relsize{-3}
 \includegraphics{tables/aaai16-5min/aaai16prelim3/evaluated-lmcut_ff-lmcut_lf.pdf}
 \includegraphics{tables/aaai16-5min/aaai16prelim3/evaluated-nokey-lmcut_ff-lmcut_r.pdf}
 \includegraphics{tables/aaai16-5min/aaai16prelim3/evaluated-nokey-lmcut_r-lmcut_lf.pdf}
 \caption{Comparisons of \# of Evaluations between simple \lifo, \fifo,
 \ro second-level tiebreaking, with first-level $h$-tiebreaking. Each
 line shows $\times 2,4,6\ldots$ boundary.}  \label{f-h-eval}
\end{figure}

According to \reftbl{single-coverage} (left) with $h$-tiebreaking, LIFO
dominates the others in Openstacks, but Random dominates the others in
Cybersec, and FIFO dominates the others in Airport, indicating that
there are no dominance relationship between these three and these
differences are purely due to the domain characteristics. From the
coverage summary, current benchmark set tends to be in favor of LIFO queue.

In \refig{f-h-eval}, we also observe Random dominates the others
in miconic.
We also confirm that the difference between several
tiebreakings are sometime larger than $\times 10$, especially in
Openstacks and Cybersec.

In \reftbl{single-coverage} (right) where the first-level
$h$-tiebreaking is disabled, the dominance of LIFO tiebreaking is
obvious in all domains.  Interestingly, the coverage by LIFO-tiebreaking
is almost comparable to LIFO with $h$-based tiebreaking and even about
to catch up with FIFO with $h$, indicating that $h$-based tiebreaking
may not be a necessity. This is a surprising result considering that
almost all of the past literature assume the importance of the $h$-based
tiebreaking and modern forward search planners employ one.

We reemphasize that, although LIFO dominated the others, we consider
this is just by a coincidence due to the selection of time limit, memory
limit and problems in the current standard IPC competition
settings. \emph{We are not trying to claim that any of LIFO or FIFO or
Random order always dominates the others}.

% However, there are noticeable
% performance difference caused by these different tiebreaking strategies.

\subsection{Size of the Plateau Matters}

We also observed that, such differences occur especially in the problems
which have the huge search plateau, i.e., the problems where the
heuristic function is not informative and the planner relies heavily on
the tiebreaking criteria.
% 
\refig{plateau} plots the size of the final search plateau with
$h$-based tiebreaking (\refig{fig:plateau-noh} in the introduction is
the same figure without $h$-tiebreaking). In this plot, $y$-axis
shows the number of nodes $[f,h]=[f^*,0]$ and $x$-axis shows the total
number of nodes $f\leq f^*$.
%  The size of the bucket does not change
% between $[f,h,\fifo]$, $[f,h,\lifo]$ and $[f,h,\ro]$.

Clearly, in some domains, the planner cound spend most of the runtime on
searching through the final plateau in the worst case: The goal node
could be found in the very last iteration in the plateau. It also
means that these domains have very large variance in the runtime caused
by the difference in second-level tiebreakings. Besides, as expected, when the
$h$-based tiebreaking is disabled in \refig{fig:plateau-noh}, much
larger effort could be spent on the final plateau.

\begin{figure}[htb]
 \centering \relsize{-3}
  \includegraphics{tables/aaai16-frontier/aaai16prelim3/lmcut_frontier-front.pdf}
  \caption{Comparing the size of the $[f,h]$ search plateau to the total
  evaluation below $f\leq f^*$. Data were obtained by the result of
  \lmcut on the standard benchmark instances. Both axes are
  logarithmic. Dotted lines represent $\times 10^n$ boundaries.
  Openstacks clearly has the large plateaus.}  \label{plateau}
\end{figure}

\todo[When we plot the same statistics on the zerocost domains, this
becomes a universal trend among instances.]{Current figure is not
plotting the zerocost domains} In cost-minimization problems, the search
strategy within plateau becomes much more important than in the
runtime-minimization instances, where most actions have nonzero cost.

\begin{figure}[htb]
 \centering \relsize{-3}
  \includegraphics{tables/aaai16-frontier/aaai16prelim3/lmcut_frontier-front.pdf}
  \caption{Same plot as \refig{plateau}, but from the zerocost
  domains. Even with $h$-tiebreaking, zerocost domains force the planner
  to search much larger plateau.}
 \label{plateau-zerocost}
\end{figure}

\subsection{Evaluating Depth-based Tiebreaking}

Next, we evaluated the 3 depth-based tiebreaking methods combined with 3
bucket implementations, resulting in 9 configurations.

Note that, the node evaluation order of $[\cdot,\fd,\fifo]$ and $[\cdot,\ld,\lifo]$
are exactly the same as those without the second-level
depth-based tiebreaking, i.e.\ $[\cdot,\fifo]$ and $[\cdot,\lifo]$.
Yet these results are useful in assessing the extra cost of managing the
depth-based buckets.

\refig{depth} shows various experiments on benchmark domains and
zerocost domains. Regardless of the third-level tiebreaking, LastDepth
strategy tends to be dominant in most domains. However, RandomDepth and
FirstDepth still exhibits a significantly better performance in Cybersec
and Mistery-Feast, respectively, indicating there is no true dominance relationship.

This result explains why the simple $[f,h,\lifo]$ strategy has become
successful.  The fact that the performance of $[f,h,\ld,\cdot]$ was
consistently good regardless of the third-level tiebreaking means that
the performance of $[f,h,\lifo]$ was actually caused by its inherent
LastDepth search pattern, and not by the implementation of LIFO
by themselves.

Supporting the above claim that the key is LastDepth and not LIFO, the
overall dominant third-level tiebreaking (in terms of coverage) is FIFO
when the second-level tiebreaking is the same.  For example, when we fix
the second-level tiebreaking, the coverages are
$[f,h,X,\fifo]>[f,h,X,\ro]>[f,h,X,\lifo]$ when $X=\ld,\rd$.
% 
Note that FIFO is bad in terms of low-level memory access
pattern since the insertion and deletion happens in the opposite side of
the bucket. It suggests that FIFO ordering is an order of magnitude
more important in many domains than the low-level performance.
% 
Still, there does exist several domains where FIFO is not dominating
the others.
For example, in Pipesworld-Pushend, the dominant third-level strategy is
RandomOrder, regardless of the second-level depth tiebreaking.
(3,3,3 in FirstDepth, 3,4,3 in RandomDepth, and 5,6,4 in LastDepth.)

% 
% However, interestingly, in RandomDepth second-level tiebreaking, the
% RandomOrder third-level tiebreaking is good in Airport-Fuel and
% Mprime-Succumb.

% Although above result suggests that the depth-based tiebreaking and
% third-level tiebreaking affects the performance,
One issue in the above analysis is that this difference might
be caused by the accidental bias in the action order in the
domain definitions.
Thus we also tested \emph{shuffled-zerocost} domains
in which we mechanically shuffled the action orderings in the
domain file. The results showed the same trends as in the original
zerocost domains. (Due to space constraint, we put this figure in the
supplementaly material.)

% Another issue in this result is the lack of analysis on
% abstraction-based heuristics. We also added the results in the figures
% in the supplemental materials. Above trends are mostly consistent when
% M\&S and blind heuristics are used, regardless of first-level
% tiebreaking by $h$-value. However, we note that many instances quickly
% exhausted the 2GB memory limit with those heuristics, and is less
% informative compared to the result by LMcut.

\begin{figure}[htb]
 \centering
 \relsize{-3}
 \input{tables/aaai16-5min/aaai16prelim3_zerocost_2zerocost_zrandom/1-1-depth-queues.tex}
 \caption{Experiments
 comparing the coverages of 9 configurations (3 depth-based strategy
 $\times$ 3 queue implementions). For the space reason, we omitted those
 domains whose results are the same. (Full results are available in the
 supplemental material.) Each cell denotes the problem solved with 30
 min, 2GB setting. \textbf{Boldface} denotes the case where it achieved
 the best result among configurations. Zerocost domains are named
 according to [original]-[name of nonzero action].}
 \label{depth}
\end{figure}

\begin{figure}[htb]
 \centering
 \relsize{-3}
 \input{tables/aaai16-5min/aaai16prelim3_zerocost_2zerocost_zrandom/1-1-depth-queues-noh.tex}
 \caption{Same experiments without first-level tiebreaking by $h$-value.}
 \label{depth-noh}
\end{figure}


\subsection{Evaluating MultiSearch Strategy}

As we see in the previous section, the planner performance is greatly
affected by the tiebreaking criteria, especially when the search plateau
is huge.
% 
Also, the more practical, cost-minimization domains tend to have large plateaus.
% 
Furthermore, the different depth-based tiebreakings are not dominating
each other, and is greatly affected by the domain characteristics.
% 
Therefore, the multisearch strategy should avoid the
worst-case scenario caused by bad tiebreaking, and quickly find the solution.

First, we show that the doubled cost of insertion and deletion by
MultiSearch is negligeble.  We verified this by running a MultiSearch
search engine with two same search engines, both using \lmcut and FIFO
queue, and compared its runtime against the same single engine (\lmcut
and FIFO). The result in \refig{ffff} shows that the extra cost of
duplicated effort is negligeble.

\begin{figure}[htbp]
 \centering
 \relsize{-2}
 % \includegraphics{tables/opt11-time-lmcut_ff-lmcut_ffff.pdf}
 \caption{Comparison of runtime on problems solved by both single FIFO search engine (ff) and a MultiSearch engine with 2 different instances of the same FIFO engine (ffff). The runtime difference was on average below a factor of x1.1, if we ignore the subsecond differences.}
 \label{ffff}
\end{figure}

Next, we evaluated our MultiSearch
strategy with selective combinations of two or three tiebreakings.
Results in \reftbl{portfolio-coverage}
shows a significant improvements compared to the results by each search
engine alone.
% 
Also, \refig{portfolio-runtime} shows the number of evaluations of these
tiebreakings compared to each search engine alone.  It shows that
MultiSearch acutally follows the expected behavior and the theoretical
bounds: the evaluation never exceeds twice/thirds of the single
search engine.

\begin{table}[htbp]
 \centering
 \relsize{-2}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_fflf.pdf}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_ffr.pdf}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_fflfr.pdf}
 \caption{Coverage results showing the performance of MultiSearch
 (X,Y,Z) dominating the single strategies.}
 \label{portfolio-coverage}
\end{table}

\begin{figure}[htbp]
 \centering
 \relsize{-2}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_fflf.pdf}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_ffr.pdf}
 % \includegraphics{tables/opt11-evaluated-lmcut_ff-lmcut_fflfr.pdf}
 \caption{Runtime comparson between MultiSearch (X,Y,Z) and single strategies.}
 \label{portfolio-runtime}
\end{figure}


\section{Related Work}
\label{sec-4}

In the realm of inadmissible search, the work on escaping the plateau is
abundant. DBFS \cite{imai2011novel} is a technique which stochastically
backtracks Greedy Best First Search to avoid being misdirected by the
heuristic function. Type based bucket \cite{xie14type} is an attempt to
classify the plateau of GBFS according to the $[g,h]$ pair.
Marvin \cite{Coles07} learns plateau-escaping macros from the Enhanced
Hill Climbing phase of the FF planner \cite{Hoffmann01} and later uses
these macros to escape the plateau.  However, to our knowledge, the
similar research on optimal planning was hardly located.

% Moved -- PLUSONE is for satisficing planning, and not directly related to tiebreaking
% Another related techinques are found in the context of satisficing planning.
An inadmissible search technique in LAMA planner \cite{richter2010lama}
increases every action costs by 1, called \emph{PLUSONE} cost-type.
It is explicitly targeted at zero-cost actions observed in Openstacks,
and resulted in a significantly better performance in IPC-6.
In PLUSONE, three successive
applications of zero-cost operators result in cost 3, and two
applications result in a cost 2, and smaller cost is preferred, just as
\astar always expands the node with smaller $f$-value.

The major difference of our depth-based tiebreaking from PLUSONE
strategy is twofold.  First, the depth used for tiebreaking does
not affect the cost, thus our algorithm does not lose the
admissibility. Next, \emph{we do not always favor smaller depth over
larger depth}. LAMA treats the increased cost as the part of
sorting criteria. In contrast, it happens only in FirstDepth configuration in our case.

%% this will invoke a request from the reviewers to compare ours against it
% Another technique in LAMA is \emph{preferred operator queue},
% which is a technique that favors those actions which decreased the
% smallest $h$ value during the search.

In admissible planning,
\emph{Symmetry Breaking}
\cite{Fox1998,pochter2011exploiting,domshlak2013symmetry} is the search
technique that tries to prune the states with symmetric
paths. \emph{Partial Order Reduction}
% , \emph{Strong Stubbern Sets} and \emph{Expansion Core} are
is also a technique which prunes the
intermediate states that reach to the same goal using the different
orders of same actions. \emph{Dominance Pruning} \cite{hall2013faster} is a
technique which prunes a state if it can be proven to be worse than the other nodes.
% 
These are usually not considered an attempt to improve the heuristic
estimates, however, in terms of \emph{Path-dependent globally admissible
heurisitics} \cite{karpas2012optimal}, a class of heuristics which is
admissible only on a particular optimal path, generalizes the above
techniques as assigining an infinite cost to some nodes on the other optimal paths.
% 
% From a slightly different category, Pathmax \cite{mero1984heuristic} and
% Bidirectional Pathmax \cite{felner2011inconsistent} are the techniques
% which converts an inconsistent heuristics into non-decreasing,
% consistent heuristics.
Thus, in a broad term, all of these methods are the
attempts to improve the heuristic estimates.
% Although in some particular
% case they may be able to return a perfect heuristics, they are still not
% always a perfect heuristics, implying that the plateau is unavoidable.
In contrast, our tiebreaking techniques aims specifically at the case
where the plateau is encountered and the planners are forced to run a
knowledge-free search.

$LA^*$ \cite{stern2010look} is an extension of \astar which employs a
\emph{lookahead} to each expansion of a node. Lookahead is a depth first
search from the frontier node limited to a particular depth $k$. When
$k=0$, called $LA^*_0$ in their paper, the greedy expansion reaches only within
the same $f$-value. It is the same as LastDepth strategy in our
case, but there is no mention comparing $LA^*_0$ to tiebreaking strategy.


TODO: relationship to line of work by Hoffmann on search topology / plateau analysis? 
\cite{Hoffmann05,Hoffmann14}


\section{Conclusion}

In this paper, we proposed two novel tie-braking methods for the admissible search using \astar. We empirically showed that they improve the performance on various domains, and they are heuristic-agnostic improvements. We showed that they have a significant impact on the final step of the search in large plateau.
 % when the distribution of optimal solutions is not uniform within the open list.
% We also showed that this nonuniform distribution still appears when we have almost-perfect % heuristics.

Our method differs from the pruning techniques because we actually
do not prune any states, nor from the other general improvements to the
heuristic accuracy because we just change the evaluation order within the
same $f$, yet it address the fundamental problems in the limitation of
heuristic forward search.  Future work includes a development of learning
technique for adaptively altering the search behavior in the plateau.



